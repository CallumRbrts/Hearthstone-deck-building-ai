@report{VGLG,
   abstract = {Generative Adversarial Networks (GANs) have shown impressive results for image generation. However, GANs face challenges in generating contents with certain types of constraints , such as game levels. Specifically, it is difficult to generate levels that have aesthetic appeal and are playable at the same time. Additionally, because training data usually is limited, it is challenging to generate unique levels with current GANs. In this paper, we propose a new GAN architecture named Conditional Embedding Self-Attention Genera-tive Adversarial Network (CESAGAN) and a new bootstrap-ping training procedure. The CESAGAN is a modification of the self-attention GAN that incorporates an embedding feature vector input to condition the training of the discriminator and generator. This allows the network to model non-local dependency between game objects, and to count objects. Additionally , to reduce the number of levels necessary to train the GAN, we propose a bootstrapping mechanism in which playable generated levels are added to the training set. The results demonstrate that the new approach does not only generate a larger number of levels that are playable but also generates fewer duplicate levels compared to a standard GAN.},
   author = {Ruben Rodriguez Torrado and Ahmed Khalifa and Michael Cerny Green and Niels Justesen and Sebastian Risi and Julian Togelius},
   title = {Bootstrapping Conditional GANs for Video Game Level Generation},
   url = {www.aaai.org},
}
@book{RSCCG,
   abstract = {In Collectible Card Games like "Magic: the Gath-ering", one of the developers' main challenges is creating new and interesting cards that are not too strong or game-braking, pertaining the game's overall balance. One way to address this issue is through the analysis of the cards resource costs. Powerful cards need more resource to be played while weaker ones need less resource. This work proposes a recommender system to a card's resource scale. In summary, we model the problem as a classification task and present and in-depth analysis of our results. We propose using LSTMs to learn a vector representation for text followed by XGBoost models to incorporate remaining features. Our approach is capable of reaching a Mean Reciprocal Rank of 0.8064 despite superficially identical cards having different mana costs. The analysis provided indicate that the model was able to learn useful rules for predicting a card's resource cost and highlight key insights for future research.},
   author = {Gianlucca Zuin and Adriano Veloso},
   isbn = {9781728118840},
   keywords = {Deep Learning,Game Balancing,Gradient Boosting,Index Terms-Collectible Card Games},
   title = {Learning a Resource Scale for Collectible Card Games},
}
@report{Denton,
   abstract = {In this paper we introduce a generative parametric model capable of producing high quality samples of natural images. Our approach uses a cascade of convo-lutional networks within a Laplacian pyramid framework to generate images in a coarse-to-fine fashion. At each level of the pyramid, a separate generative con-vnet model is trained using the Generative Adversarial Nets (GAN) approach [11]. Samples drawn from our model are of significantly higher quality than alternate approaches. In a quantitative assessment by human evaluators, our CIFAR10 samples were mistaken for real images around 40% of the time, compared to 10% for samples drawn from a GAN baseline model. We also show samples from models trained on the higher resolution images of the LSUN scene dataset.},
   author = {Emily Denton and Soumith Chintala and Arthur Szlam and Rob Fergus},
   title = {Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks},
}
@report{NIPS2016,
   abstract = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
   author = {Ian Goodfellow Openai},
   title = {NIPS 2016 Tutorial: Generative Adversarial Networks},
   url = {http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf},
}
@report{NIPS2014,
   abstract = {We propose a new framework for estimating generative models via an adversar-ial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1 2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
   author = {Ian J Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
   title = {Generative Adversarial Nets},
   url = {http://www.github.com/goodfeli/adversarial},
}
@article{MapElites,
   abstract = {Quality diversity (QD) algorithms such as MAP-Elites have emerged as a powerful alternative to traditional single-objective optimization methods. They were initially applied to evolutionary robotics problems such as locomotion and maze navigation, but have yet to see widespread application. We argue that these algorithms are perfectly suited to the rich domain of video games, which contains many relevant problems with a multitude of successful strategies and often also multiple dimensions along which solutions can vary. This paper introduces a novel modification of the MAP-Elites algorithm called MAP-Elites with Sliding Boundaries (MESB) and applies it to the design and rebalancing of Hearthstone, a popular collectible card game chosen for its number of multidimensional behavior features relevant to particular styles of play. To avoid overpopulating cells with conflated behaviors, MESB slides the boundaries of cells based on the distribution of evolved individuals. Experiments in this paper demonstrate the performance of MESB in Hearthstone. Results suggest MESB finds diverse ways of playing the game well along the selected behavioral dimensions. Further analysis of the evolved strategies reveals common patterns that recur across behavioral dimensions and explores how MESB can help rebalance the game.},
   author = {Matthew C Fontaine and Scott Lee and L B Soros and Fernando De and Mesentier Silva and Julian Togelius and Amy K Hoover},
   doi = {10.1145/nnnnnnn.nnnnnnn},
   keywords = {Balancing,Card games,Games,Hearthstone,Illumination algorithms,Quality diversity},
   title = {Mapping Hearthstone Deck Spaces through MAP-Elites with Sliding Boundaries},
   url = {https://arxiv.org/pdf/1904.10656.pdf},
}
@web_page{HS,
   title = {Hearthstone},
   url = {https://playhearthstone.com/en-us},
}
@web_page{CCG,
   title = {Collectible card game - Wikipedia},
   url = {https://en.wikipedia.org/wiki/Collectible_card_game},
}
@article{PredictWR,
   abstract = {Success of many computer games depends on designing a robust and adaptable AI opponent that would ensure the games continue to challenge, immerse and excite the players at any stage. The outcomes of card based games like "Heartstone: Heros of Warcraft", aside the player skills heavily depend on the initial composition of player card decks. To evaluate this impact we have developed an ensemble prediction model that tries to predict the average win-rates of the specific combination of bot-player and card decks. Our ensemble model consists of three sub-models: two Logistic Regression models and one Deep Learning model. The models are trained with both provided data and additional data about the cards, their health, attack power and cost. To avoid overfitting, we employ a trick to generate predictions for all possible combinations of opponent players and decks and obtain the result as the average of all these predictions.},
   author = {Quang Hieu Vu and Dymitr Ruta and Andrzej Ruta and Ling Cen},
   doi = {10.15439/2018F363},
   title = {Predicting Win-rates of Hearthstone Decks: Models and Features that Won AAIA'2018 Data Mining Challenge},
   url = {http://hearthstoneapi.com/.},
}
@article{NNWRPrediction,
   abstract = {This paper describes a solution to the AAIA'18 data mining challenge, which concerns prediction of win rates for decks in Hearthstone collectible card game. A neural network model assigning win rate to decks is learned based on maximisa-tion of log probability of observed match results. A representation of deck contents is based on a second network, which performs the role of a dual-task encoder. Two tasks learned by the encoding networks are encoding decks in such a way that the full deck can be reconstructed, and encoding individual cards so that their specific properties can be decoded. Shared representation for these tasks allows the knowledge of individual cards to be taken into account.},
   author = {Jan Jakubik},
   doi = {10.15439/2018F365},
   title = {A Neural Network Approach to Hearthstone Win Rate Prediction},
}
@report{Ward2020,
   abstract = {1 Abstract Drafting in Magic: the Gathering is a sub-game of a larger trading card game, where several players progressively build decks by picking cards from a common pool. Drafting poses an interesting problem for game-playing and AI research due to its large search space, mechanical complexity, multiplayer nature, and hidden information. Despite this, drafting remains understudied in part due to a lack of high-quality, public datasets. To rectify this problem, we present a dataset of over 100,000 simulated, anonymized human drafts collected from Draftsim.com. Additionally, we propose four diverse strategies for drafting agents, including a primitive heuristic agent, an expert-tuned complex heuristic agent, a Naive Bayes agent, and a deep neural network agent. We benchmark their ability to emulate human drafting, and show that the deep neural network agent outperforms all other agents, while Naive Bayes and expert-tuned agents outperform simple heuristics. We analyze the accuracy of AI agents across the timeline of a draft, for different cards, and in terms of approximating subtle inconsistencies of human behavior, and describe unique strengths and weaknesses for each agent. This work helps to identify next steps in the creation of humanlike drafting agents, and can serve as a set of useful benchmarks for the next generation of drafting bots. 2 Introduction AI agents have recently achieved superhuman performance in several challenging games such as chess, shogi, go, and poker [1, 2, 3], as well real-time strategy games such as StarCraft II and multiplayer online battle arenas (MOBAs) such as Dota 2 [4, 5]. These successes open opportunities to branch out and to create game-playing AI for other complex games. Much like strategy and MOBA games, collectible card games (CCGs) such as Hearthstone and Magic: the Gathering (MtG) present challenging milestones for AI, due to their mechanical complexity, multiplayer nature, and large amount of hidden information [6]. Although some studies investigate AI for Hearthstone [7, 8, 9, 10], relatively little work exists on building game-playing AI for MtG [11, 12]. In this paper, we focus on a game mode known as "drafting" that involves progressive deck-building, where players take turns to select cards for their collection from given initial sets of cards [13]. From their final collections, each player builds a deck and plays games against each other to determine the winner of the draft. We focus on drafting in Magic: the Gathering. MtG features one of the most complicated and popular drafting environments, where eight players each open a pack of 15 semi-random cards, select one card from that pack, and pass the remainder of the pack},
   author = {Henry N Ward and Daniel J Brooks and Dan Troha and Bobby Mills and Arseny S Khakhalin},
   title = {AI solutions for drafting in Magic: the Gathering},
   year = {2020},
}

@web_page{BvsP,
   author = {CCGer},
   year = {2011},
   title = {Deck building vs skillfull play. 29th December.},
   url = {https://www.mtgsalvation.com/forums/magic-fundamentals/magic-general/327490-deck-building-vs-skillfull-play  },
   note = {[Accessed: 27/10/20].}
}
@web_page{SvsL,
   title = {What is Skill and Luck - Multiplayer Discussion - Hearthstone Forums},
   url = {https://us.forums.blizzard.com/en/hearthstone/t/what-is-skill-and-luck/4415},
}
@report{EvolveMeta,
   abstract = {Balancing an ever growing strategic game of high complexity, such as Hearthstone is a complex task. The target of making strategies diverse and customizable results in a delicate intricate system. Tuning over 2000 cards to generate the desired outcome without disrupting the existing environment becomes a laborious challenge. In this paper, we discuss the impacts that changes to existing cards can have on strategy in Hearthstone. By analyzing the win rate on match-ups across different decks, being played by different strategies, we propose to compare their performance before and after changes are made to improve or worsen different cards. Then, using an evolutionary algorithm, we search for a combination of changes to the card attributes that cause the decks to approach equal, 50% win rates. We then expand our evolutionary algorithm to a multi-objective solution to search for this result, while making the minimum amount of changes, and as a consequence disruption, to the existing cards. Lastly, we propose and evaluate metrics to serve as heuristics with which to decide which cards to target with balance changes.},
   author = {Fernando De and Mesentier Silva and Matthew C Fontaine and Rodrigo Canaan and Julian Togelius and Scott Lee and Amy K Hoover},
   keywords = {Game Balancing,Hearthstone,Index Terms-Evolutionary Algorithm,Multi-Objective Opti-mization},
   title = {Evolving the Hearthstone Meta},
   url = {https://github.com/HearthSim/SabberStone},
}

@web_page{Judlick,
   author = {James Judlick},
   title = {Identifying Deck Archetypes - Articles - Tempo Storm},
   url = {https://tempostorm.com/articles/identifying-deck-archetypes},
}
@web_page{Robertson2016,
   title = {Jungian Archetypes: Jung, Gödel, and the History of Archetypes },
   author = {Robin Robertson },
   year = {2016},
   publisher = {Open Road Distribution},
   url = {https://books.google.fr/books?hl=en&lr=&id=tLJgDAAAQBAJ&oi=fnd&pg=PT7&dq=jungian+archetypes&ots=56eqtqa6K_&sig=Tmk2iRpe1XHy9l_kFD3Yc_N-Gnc&redir_esc=y#v=onepage&q=jungian%20archetypes&f=false},
}
@web_page{Standard,
   title = {Standard format},
   author = {Gamepedia},
   year = {2020},
   url = {https://hearthstone.gamepedia.com/Standard_format},
   note ={[Accessed: 04/11/20].},
}
@book{Zuin2019,
   abstract = {In Collectible Card Games like "Magic: the Gath-ering", one of the developers' main challenges is creating new and interesting cards that are not too strong or game-braking, pertaining the game's overall balance. One way to address this issue is through the analysis of the cards resource costs. Powerful cards need more resource to be played while weaker ones need less resource. This work proposes a recommender system to a card's resource scale. In summary, we model the problem as a classification task and present and in-depth analysis of our results. We propose using LSTMs to learn a vector representation for text followed by XGBoost models to incorporate remaining features. Our approach is capable of reaching a Mean Reciprocal Rank of 0.8064 despite superficially identical cards having different mana costs. The analysis provided indicate that the model was able to learn useful rules for predicting a card's resource cost and highlight key insights for future research.},
   year = {2019},
   author = {Gianlucca Zuin and Adriano Veloso},
   isbn = {9781728118840},
   keywords = {Deep Learning,Game Balancing,Gradient Boosting,Index Terms-Collectible Card Games},
   title = {Learning a Resource Scale for Collectible Card Games},
}

@article{Howard2019,
   abstract = {“Casual” and “hardcore” are commonly used descriptive terms for games and gamers. While critics have discussed these terms with regards to game design and culture, “free-to-play” games like Blizzard’s Hearthstone add a monetary dimension to such considerations. Players can play such games for free, but success at them often entails purchasing in-game content. These games are sometimes instead derisively referred to as “pay-to-win:” players who spend money win more often. Free-to-play games suggest that casual and hardcore depend on how much money a player spends on the game, in addition to measures like time investment or play practices. I argue that free-to-play games encourage casual players to become more hardcore by spending more money on them in addition to improving their skills at the game, using Hearthstone as a case study to examine the implications of the free-to-play pricing structure on both game design and game players.},
   author = {Kenton Taylor Howard},
   doi = {10.26503/todigra.v4i3.103},
   issn = {2328-9414},
   issue = {3},
   journal = {Transactions of the Digital Games Research Association},
   keywords = {Hearthstone,casual games,collectible card games,free-to-play games,hardcore games},
   month = {10},
   pages = {147-169},
   publisher = {Digital Games Research Association},
   title = {Free-to-Play or Pay-to-Win? Casual, Hardcore, and Hearthstone},
   volume = {4},
   url = {http://todigra.org/index.php/todigra/article/view/103},
   year = {2019},
}
@report{Sweetser2002,
   abstract = {As the graphics race subsides and gamers grow weary of predictable and deterministic game characters, game developers must put aside their "old faithful" finite state machines and look to more advanced techniques that give the users the gaming experience they crave. The next industry breakthrough will be with characters that behave realistically and that can learn and adapt, rather than more polygons, higher resolution textures and more frames-per-second. This paper explores the various artificial intelligence techniques that are currently being used by game developers, as well as techniques that are new to the industry. The techniques covered in this paper are finite state machines, scripting, agents, flocking, fuzzy logic and fuzzy state machines decision trees, neural networks, genetic algorithms and extensible AI. This paper introduces each of these technique, explains how they can be applied to games and how commercial games are currently making use of them.
   Finally, the effectiveness of these techniques and their future role in the industry are evaluated.},
   author = {Sweetser, P. and Wiles, J.},
   year = {2002},
   keywords = {artificial intelligence,computer games},
   title = {Current AI in Games: A Review},
}
@web_page{100mil,
   title = {Celebrating 100 Million Players!},
   url = {https://playhearthstone.com/en-us/news/22636890},
   year = {2018},
   author = {Blizzard Entertainment},
   note = {[Accessed: 05/11/20]}
}
@book{yannakakis2018artificial,
    title={{Artificial Intelligence and Games}},
    author={Georgios N. Yannakakis and Julian Togelius},
    publisher={Springer},
    url = {http://gameaibook.org},
    note={pp 119-148},
    year={2018},
}
@report{Hoover2019,
   abstract = {Games have benchmarked AI methods since the inception of the field, with classic board games such as Chess and Go recently leaving room for video games with related yet different sets of challenges. The set of AI problems associated with video games has in recent decades expanded from simply playing games to win, to playing games in particular styles, generating game content , modeling players etc. Different games pose very different challenges for AI systems, and several different AI challenges can typically be posed by the same game. In this article we analyze the popular collectible card game Hearthstone (Blizzard 2014) and describe a varied set of interesting AI challenges posed by this game. Collectible card games are relatively understud-ied in the AI community, despite their popularity and the interesting challenges they pose. Analyzing a single game in-depth in the manner we do here allows us to see the entire field of AI and Games through the lens of a single game, discovering a few new variations on existing research topics.},
   author = {Amy K Hoover and Julian Togelius and Scott Lee and Fernando De Mesentier Silva and Fernando De and Mesentier Silva},
   keywords = {Artificial,Deckbuilding ·,Gameplaying ·,Games ·,Hearth-stone ·,Intelligence ·,Modeling,Player},
   title = {The Many AI Challenges of Hearthstone},
   url = {https://hearthsim.info/},
   year = {2019},
}
@report{Janusz2017,
   abstract = {This paper summarizes the AAIA'17 Data Mining Challenge: Helping AI to Play Hearthstone which was held between March 23, and May 15, 2017 at the Knowledge Pit platform. We briefly describe the scope and background of this competition in the context of a more general project related to the development of an AI engine for video games, called Grail. We also discuss the outcomes of this challenge and demonstrate how predictive models for the assessment of player's winning chances can be utilized in a construction of an intelligent agent for playing Hearthstone. Finally, we show a few selected machine learning approaches for modeling state and action values in Hearthstone. We provide evaluation for a few promising solutions that may be used to create more advanced types of agents, especially in conjunction with Monte Carlo Tree Search algorithms.},
   author = {Andrzej Janusz and Tomasz Tajmajer and Maciej´swiechowski Maciej´ Maciej´swiechowski},
   keywords = {AI in video games,Hearthstone: Heroes of Warcraft,MCTS,artificial neural networks,data mining competition},
   title = {Helping AI to Play Hearthstone: AAIA'17 Data Mining Challenge},
   url = {https://knowledgepit.fedcsis.org/contest/view.},
   year = {2017},
}

@report{Miguel2017,
   author = {André Miguel},
   title = {Monte Carlo Tree Search Experiments in Hearthstone Information Systems and Computer Engineering Examination Committee},
   year = {2017},
   url = {https://www.researchgate.net/profile/Andre_Santos62/publication/317904983_Monte_Carlo_Tree_Search_experiments_in_Hearthstone/links/5977b48aa6fdcc30bdbadc2a/Monte-Carlo-Tree-Search-experiments-in-Hearthstone.pdf},
}
@report{Swiechowski2018,
   abstract = {Warning: this is not the final camera-ready version. Abstract We investigate the impact of supervised prediction models on the strength and efficiency of artificial agents that use the Monte-Carlo Tree Search (MCTS) algorithm to play a popular video game Hearthstone: Heroes of Warcraft. We overview our custom implementation of the MCTS that is well-suited for games with partially hidden information and random effects. We also describe experiments which we designed to quantify the performance of our Hearthstone agent's decision making. We show that even simple neural networks can be trained and successfully used for the evaluation of game states. Moreover, we demonstrate that by providing a guidance to the game state search heuristic, it is possible to substantially improve the win rate, and at the same time reduce the required computations.},
   author = {Maciej´swiechowski and Tomasz Tajmajer and Andrzej Janusz},
   keywords = {Hearthstone,Index Terms-MCTS,heuristic,machine learning,neural networks},
   title = {Improving Hearthstone AI by Combining MCTS and Supervised Learning Algorithms},
   url = {https://arxiv.org/pdf/1808.04794.pdf},
   year = {2018},
}
@book{Back1996,
   title = {Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms},
   author =  {Thomas Back},
   year = {1996},
   publisher = {Oxford University Press},
   url = {https://books.google.fr/books?hl=en&lr=&id=htJHI1UrL7IC&oi=fnd&pg=PR9&dq=evolutionary+algorithms&ots=fBl_1QSCiT&sig=g5AzYmN078gAvTVrxhGqfPW-Ieg&redir_esc=y#v=onepage&q=evolutionary%20algorithms&f=false},
}
@web_page{Kowalczyk2013,
   title = {Writing Research Questions: Purpose and Examples},
   author = {Devin Kowalczyk},
   year = {2013},
   note = {[Accessed: 07/11/20]},
   url = {https://study.com/academy/lesson/writing-research-questions-purpose-examples.html},
}
@report{Bursztein2016,
   abstract = {In this paper, we demonstrate the feasibility of a competitive player using statistical learning methods to gain an edge while playing a collectible card game (CCG) online. We showcase how our attacks work in practice against the most popular online CCG, Hearthstone: Heroes of World of Warcraft, which had over 50 million players as of April 2016. Like online poker, the large and regular cash prizes of Hearthstone's online tournaments make it a prime target for cheaters in search of a quick score. As of 2016, over $3,000,000 in prize money has been distributed in tournaments, and the best players earned over $10,000 from purely online tournaments. In this paper, we present the first algorithm that is able to learn and exploit the structure of card decks to predict with very high accuracy which cards an opponent will play in future turns. We evaluate it on real Hearthstone games and show that at its peak, between turns three and five of a game, this algorithm is able to predict the most probable future card with an accuracy above 95%. This attack was called "game breaking" by Blizzard, the creator of Hearthstone.},
   author = {Elie Bursztein},
   year = {2016},
   publisher = {IEEE},
  journal = {IEEE Conference on Computational Intelligenceand Games, CIG 2016, Santorini, Greece, September 20-23, 2016},
   title = {I am a legend: hacking Hearthstone using statistical learning methods},
   note = {pp. 1–8.},
   url = {https://elie.net/static/files/i-am-a-legend-hacking-hearthstone-using-statistical-learning-methods/i-am-a-legend-hacking-hearthstone-using-statistical-learning-methods-paper.pdf},
}
@web_page{Flipperbw2014,
   title = {Simple Hearthstone logging - see your complete play history without TCP, screen capture, or violating the TOS},
   author = {Flipperbw},
   year = {2014},
   url = {https://www.reddit.com/r/hearthstone/comments/268fkk/simple_hearthstone_logging_see_your_complete_play/},
   note = {[Accessed: 08/11/20].},
}
@report{Agrawal1994,
   abstract = {We consider the problem of discovering association rules between items in a large database of sales transactions. We present two new algorithms for solving this problem that are fundamentally diierent from the known algorithms. Experiments with synthetic as well as real-life data show that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. We also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called AprioriHybrid. Scale-up experiments show that AprioriHybrid scales linearly with the number of transactions. AprioriHybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database.},
   author = {Rakesh Agrawal and Ramakrishnan Srikant},
   title = {Fast Algorithms for Mining Association Rules},
   year = {1994},
}
@inproceedings{Stiegler2017,
   abstract = {Trading Card Games are turn-based games involving strategic planning, synergies and rather complex gameplay. An interesting aspect of this game domain is the strong influence of their metagame: in this particular case deck-construction. Before a game starts, players select which cards from a vast card pool they want to take into the current game session, defining their available options and a great deal of their strategy. We introduce an approach to do automatic deck construction for the digital Trading Card Game Hearthstone, based on a utility system utilizing several metrics to cover gameplay concepts such as cost effectiveness, the mana curve, synergies towards other cards, strategic parameters about a deck as well as data on how popular a card is within the community. The presented approach aims to provide useful information about a deck for a player-level AI playing the actual game session at runtime. Herein, the key use case is to store information on why cards were included and how they should be used in the context of the respective deck. Besides creating new decks from scratch, the algorithm is also capable of filling holes in existing deck skeletons, fitting an interesting use case for Human Hearthstone players: adapting a deck to their specific pool of available cards. After introducing the algorithms and describing the different utility sources used, we evaluate how the algorithm performs in a series of experiments filling holes in existing decks of the Hearthstone eSports scene.},
   author = {Andreas Stiegler and Claudius Messerschmidt and Johannes Maucher and Keshav Dahal},
   doi = {10.1109/SKIMA.2016.7916192},
   isbn = {9781509032976},
   journal = {SKIMA 2016 - 2016 10th International Conference on Software, Knowledge, Information Management and Applications},
   keywords = {TCG,adversarial environment,deck-construction,knowledge aggregaton,metagame,utility system},
   month = {5},
   pages = {21-28},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Hearthstone deck-construction with a utility system},
   year = {2017},
}
@report{Fludal2017,
   author = {Sverre Johann Bjørke and Knut Aron Fludal},
   keywords = {Databaser og søk,Informatikk,Kunstig intelligens},
   publisher = {NTNU},
   title = {Sverre Johann Bjørke Knut Aron Fludal Deckbuilding in Magic: The Gathering Using a Genetic Algorithm},
   url = {https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/2462429},
   year = {2017},
}
@article{Whitley1994,
   abstract = {This tutorial covers the canonical genetic algorithm as well as more experimental forms of genetic algorithms, including parallel island models and parallel cellular genetic algorithms. The tutorial also illustrates genetic search by hyperplane sampling. The theoretical foundations of genetic algorithms are reviewed, include the schema theorem as well as recently developed exact models of the canonical genetic algorithm. © 1994 Chapman & Hall.},
   author = {Darrell Whitley},
   doi = {10.1007/BF00175354},
   issn = {09603174},
   issue = {2},
   journal = {Statistics and Computing},
   keywords = {Genetic algorithms,parallel algorithms,search},
   month = {6},
   pages = {65-85},
   publisher = {Kluwer Academic Publishers},
   title = {A genetic algorithm tutorial},
   volume = {4},
   url = {https://link.springer.com/article/10.1007/BF00175354},
   year = {1994},
}
@article{GarciaSanchez2018,
title = {Automated playtesting in collectible card games using evolutionary algorithms: A case study in hearthstone},
journal = {Knowledge-Based Systems},
volume = {153},
pages = {133 - 146},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.04.030},
url = {http://www.sciencedirect.com/science/article/pii/S0950705118301953},
author = {Pablo García-Sánchez and Alberto Tonda and Antonio M. Mora and Giovanni Squillero and Juan Julián Merelo},
keywords = {Genetic algorithm, Hearthstone, Collectible card games, Artificial intelligence},
abstract = {Collectible card games have been among the most popular and profitable products of the entertainment industry since the early days of Magic: The GatheringTM in the nineties. Digital versions have also appeared, with HearthStone: Heroes of WarCraftTM being one of the most popular. In Hearthstone, every player can play as a hero, from a set of nine, and build his/her deck before the game from a big pool of available cards, including both neutral and hero-specific cards. This kind of games offers several challenges for researchers in artificial intelligence since they involve hidden information, unpredictable behaviour, and a large and rugged search space. Besides, an important part of player engagement in such games is a periodical input of new cards in the system, which mainly opens the door to new strategies for the players. Playtesting is the method used to check the new card sets for possible design flaws, and it is usually performed manually or via exhaustive search; in the case of Hearthstone, such test plays must take into account the chosen hero, with its specific kind of cards. In this paper, we present a novel idea to improve and accelerate the playtesting process, systematically exploring the space of possible decks using an Evolutionary Algorithm (EA). This EA creates HearthStone decks which are then played by an AI versus established human-designed decks. Since the space of possible combinations that are play-tested is huge, search through the space of possible decks has been shortened via a new heuristic mutation operator, which is based on the behaviour of human players modifying their decks. Results show the viability of our method for exploring the space of possible decks and automating the play-testing phase of game design. The resulting decks, that have been examined for balancedness by an expert player, outperform human-made ones when played by the AI; the introduction of the new heuristic operator helps to improve the obtained solutions, and basing the study on the whole set of heroes shows its validity through the whole range of decks.}
}
@book{Eiben2015,
   author = {A.E. Eiben and J.E. Smith},
   city = {Berlin, Heidelberg},
   doi = {10.1007/978-3-662-44874-8},
   isbn = {978-3-662-44873-1},
   publisher = {Springer Berlin Heidelberg},
   title = {Introduction to Evolutionary Computing},
   url = {http://link.springer.com/10.1007/978-3-662-44874-8},
   year = {2015},
}
@inproceedings{GarciaSanchez2016,
   abstract = {One of the most notable features of collectible card games is deckbuilding, that is, defining a personalized deck before the real game. Deckbuilding is a challenge that involves a big and rugged search space, with different and unpredictable behaviour after simple card changes and even hidden information. In this paper, we explore the possibility of automated deckbuilding: a genetic algorithm is applied to the task, with the evaluation delegated to a game simulator that tests every potential deck against a varied and representative range of human-made decks. In these preliminary experiments, the approach has proven able to create quite effective decks, a promising result that proves that, even in this challenging environment, evolutionary algorithms can find good solutions.},
   author = {Pablo Garcia-Sanchez and Alberto Tonda and Giovanni Squillero and Antonio Mora and Juan J. Merelo},
   doi = {10.1109/CIG.2016.7860426},
   isbn = {9781509018833},
   issn = {23254289},
   journal = {IEEE Conference on Computatonal Intelligence and Games, CIG},
   month = {7},
   publisher = {IEEE Computer Society},
   title = {Evolutionary deckbuilding in hearthstone},
   volume = {0},
   year = {2016},
}
@book_section{Janikow1993,
   author = {Cezary Z. Janikow},
   doi = {10.1007/978-1-4615-2740-4_3},
   journal = {Genetic Algorithms for Machine Learning},
   pages = {33-72},
   publisher = {Springer US},
   title = {A Knowledge-Intensive Genetic Algorithm for Supervised Learning},
   url = {https://link.springer.com/chapter/10.1007/978-1-4615-2740-4_3},
   year = {1993},
}
@INPROCEEDINGS{Merelo2015,
  author={J. J. {Merelo} and F. {Liberatore} and A. F. {Ares} and R. {García} and Z. {Chelly} and C. {Cotta} and N. {Rico} and A. M. {Mora} and P. {García-Sánchez}},
  booktitle={2015 7th International Joint Conference on Computational Intelligence (IJCCI)},
  title={There is noisy lunch: A study of noise in evolutionary optimization problems},
  year={2015},
  volume={1},
  number={},
  pages={261-268},
  doi={}
}
@book{burkov2019,
  title={The Hundred-Page Machine Learning Book},
  author={Burkov, A.},
  isbn={9781999579517},
  url={https://books.google.fr/books?id=0jbxwQEACAAJ},
  year={2019},
  publisher={Andriy Burkov}
}

@article{Facundo2017,
  author = {Bre, Facundo and Gimenez, Juan and Fachinotti, Víctor},
  year = {2017},
  month = {11},
  pages = {},
  title = {Prediction of wind pressure coefficients on building surfaces using Artificial Neural Networks},
  volume = {158},
  journal = {Energy and Buildings},
  doi = {10.1016/j.enbuild.2017.11.045}
}

@online{3blue1brown,
   title = { But what is a Neural Network? | Deep learning, chapter 1},
   author = {3blue1brown},
   organisation = {Youtube},
   date = {05/10/17},
   year = {2017},
   url = {https://www.youtube.com/watch?v=aircAruvnKk},
   note = {[Accessed: 25/10/20]},
}
@INPROCEEDINGS{Sehgal2019,
  author={A. {Sehgal} and H. {La} and S. {Louis} and H. {Nguyen}},
  booktitle={2019 Third IEEE International Conference on Robotic Computing (IRC)},
  title={Deep Reinforcement Learning Using Genetic Algorithm for Parameter Optimization},
  year={2019},
  volume={},
  number={},
  pages={596-601},
  doi={10.1109/IRC.2019.00121}
}
@article{Such2017,
   abstract = {Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient. That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of neuroevolution techniques that improve performance. We demonstrate the latter by showing that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g.\ DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN (it can train Atari in $\{\raise.17ex\hbox\{$\scriptstyle\sim$\}\}$4 hours on one desktop or $\{\raise.17ex\hbox\{$\scriptstyle\sim$\}\}$1 hour distributed on 720 cores), and enables a state-of-the-art, up to 10,000-fold compact encoding technique.},
   author = {Felipe Petroski Such and Vashisht Madhavan and Edoardo Conti and Joel Lehman and Kenneth O. Stanley and Jeff Clune},
   month = {12},
   title = {Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning},
   url = {http://arxiv.org/abs/1712.06567},
   year = {2017},
}
@article{Nigam2019,
   abstract = {Challenges in natural sciences can often be phrased as optimization problems. Machine learning techniques have recently been applied to solve such problems. One example in chemistry is the design of tailor-made organic materials and molecules, which requires efficient methods to explore the chemical space. We present a genetic algorithm (GA) that is enhanced with a neural network (DNN) based discriminator model to improve the diversity of generated molecules and at the same time steer the GA. We show that our algorithm outperforms other generative models in optimization tasks. We furthermore present a way to increase interpretability of genetic algorithms, which helped us to derive design principles.},
   author = {AkshatKumar Nigam and Pascal Friederich and Mario Krenn and Alán Aspuru-Guzik},
   journal = {arXiv},
   month = {9},
   publisher = {arXiv},
   title = {Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space},
   url = {http://arxiv.org/abs/1909.11655},
   year = {2019},
}
